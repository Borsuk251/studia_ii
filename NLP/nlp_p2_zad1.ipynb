{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_p2_zad1",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEiAZRSekyYy",
        "outputId": "52cbf25a-c2f2-4bbf-95c7-deac31184cda"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJEuc854k37X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb5bd61-a004-474f-e48e-a67547fb77e9"
      },
      "source": [
        "import string\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "%cd '/content/drive/My Drive/nlp'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/nlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP21PfXH-58K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tf-44QxsEd4"
      },
      "source": [
        "def create_corpus_orzeszkowa():\n",
        "  corpus = {}\n",
        "  validate = []\n",
        "  sent_lengths = {}\n",
        "  with open('/content/drive/My Drive/nlp/korpus_orzeszkowej.txt', 'r', encoding = 'utf8') as file:\n",
        "   i=0\n",
        "   for  line in file:\n",
        "    if line == '\\n': continue\n",
        "    i+=1\n",
        "    if i%5 == 0:\n",
        "      validate.append(line)\n",
        "      continue\n",
        "    words = line.split()\n",
        "    sen_len = 1\n",
        "    for word in words:\n",
        "      if word == '—':\n",
        "        continue\n",
        "      if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "        sen_len +=1\n",
        "      else:\n",
        "        if sen_len in sent_lengths:\n",
        "          sent_lengths[sen_len] = sent_lengths[sen_len]+1\n",
        "        else:\n",
        "          sent_lengths[sen_len] = 1\n",
        "        sen_len = 0\n",
        "    for word in words:\n",
        "      if word in corpus:\n",
        "        num = corpus[word]\n",
        "        corpus[word] = num + 1\n",
        "      else:\n",
        "        corpus[word] = 1\n",
        "  return corpus, i, validate, sent_lengths\n",
        "\n",
        "corpus_orz, orz_size, val_orz, SL_orz = create_corpus_orzeszkowa()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvyYFCsB-_CF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6g-rXkTzCGV",
        "outputId": "be521782-6119-448d-fa04-4aa52831f8fb"
      },
      "source": [
        "print(SL_orz)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{20: 248, 29: 101, 2: 1120, 14: 365, 17: 292, 19: 229, 15: 290, 30: 94, 1: 606, 13: 344, 4: 759, 57: 11, 16: 292, 3: 923, 5: 724, 0: 547, 28: 117, 68: 4, 27: 127, 12: 411, 42: 46, 11: 390, 18: 242, 22: 177, 10: 440, 39: 49, 34: 67, 35: 67, 24: 170, 32: 93, 40: 41, 7: 544, 26: 176, 25: 183, 38: 53, 49: 18, 23: 202, 37: 39, 53: 13, 8: 516, 44: 32, 45: 21, 9: 448, 6: 599, 21: 193, 60: 7, 70: 3, 31: 76, 36: 50, 74: 3, 33: 67, 43: 36, 47: 27, 52: 12, 100: 1, 56: 16, 51: 14, 41: 32, 48: 14, 50: 17, 75: 3, 46: 15, 54: 13, 55: 9, 63: 9, 64: 8, 62: 10, 67: 2, 71: 2, 107: 1, 72: 3, 99: 1, 105: 1, 84: 1, 106: 1, 59: 3, 79: 1, 104: 1, 58: 9, 82: 3, 61: 4, 78: 3, 73: 4, 66: 5, 85: 1, 69: 2, 92: 1, 102: 1, 91: 1, 77: 3, 80: 1, 86: 2, 98: 1, 83: 1, 76: 1, 202: 1, 110: 2, 375: 1, 809: 1, 1589: 1, 592: 1, 123: 1, 1225: 1, 210: 1, 144: 1, 908: 1, 179: 1, 574: 1, 116: 1, 89: 1, 286: 1, 423: 1, 163: 1, 614: 1, 457: 1, 115: 1, 93: 1, 864: 1, 112: 1, 356: 1, 308: 1, 743: 1, 154: 1, 382: 1, 877: 1, 904: 1, 342: 1, 579: 1, 556: 1, 328: 1, 177: 1, 838: 1, 267: 1, 164: 1, 273: 1, 561: 1, 155: 1, 96: 1, 111: 1, 101: 1, 280: 1, 1196: 1, 318: 1, 65: 1, 249: 1, 182: 1, 222: 1, 385: 1, 185: 1, 551: 1, 171: 1, 217: 1, 1278: 1, 97: 1, 567: 1, 452: 1, 137: 1, 1151: 1, 511: 1, 271: 1, 238: 1, 1084: 1, 125: 1, 346: 1, 546: 1, 194: 1, 244: 1, 252: 1, 191: 1, 237: 1, 190: 1, 1049: 1, 180: 1, 478: 1, 212: 1, 315: 1, 95: 1, 998: 1, 229: 1, 332: 1, 128: 1, 121: 1, 159: 1, 246: 1, 153: 1, 1363: 1, 378: 1, 133: 1, 132: 1, 1059: 1, 461: 1, 464: 1, 118: 1, 81: 1, 1627: 1, 427: 1, 129: 1, 352: 1, 146: 1, 257: 1, 528: 1, 114: 1, 195: 1, 284: 1, 196: 1, 843: 1, 1766: 1, 2395: 1, 209: 1, 168: 1, 523: 1, 529: 1, 403: 1, 289: 1, 141: 1, 215: 1, 398: 1, 138: 1, 139: 1, 149: 1, 499: 1, 627: 1, 874: 1, 411: 1, 493: 1, 846: 1, 312: 1, 795: 1, 628: 1, 265: 1, 584: 1, 314: 1, 348: 1, 126: 1, 113: 1, 178: 1, 233: 1, 601: 1, 208: 1, 127: 1, 206: 1, 1219: 1, 189: 1, 143: 1, 343: 1, 645: 1, 1316: 1, 181: 1, 941: 1, 1030: 1, 151: 1, 162: 1, 706: 1, 484: 1, 1170: 1, 158: 1, 299: 1, 331: 1, 192: 1, 274: 1, 156: 1, 239: 1, 135: 1, 293: 1, 193: 1, 1379: 1, 956: 1, 173: 1, 322: 1, 187: 1, 134: 1, 407: 1, 150: 1, 334: 1, 431: 1, 805: 1, 175: 1, 87: 1, 221: 1, 169: 1, 752: 1, 232: 1, 349: 1, 152: 1, 117: 1, 1036: 1, 109: 1, 357: 1, 160: 1, 473: 1, 262: 1, 292: 1, 354: 1, 424: 1, 640: 1, 241: 1, 329: 1, 320: 1, 142: 1, 384: 1, 1257: 1, 1401: 1, 737: 1, 170: 1, 1454: 1, 157: 1, 94: 1, 108: 1, 316: 1, 409: 1, 459: 1, 240: 1, 387: 1, 954: 1, 651: 1, 999: 1, 1426: 1, 436: 1, 370: 1, 234: 1, 1055: 1, 400: 1, 300: 1, 122: 1, 88: 1, 140: 1, 136: 1, 268: 1, 204: 1, 559: 1, 276: 1, 1010: 1, 444: 1, 148: 1, 166: 1, 525: 1, 225: 1, 978: 1, 505: 1, 359: 1, 716: 1, 986: 1, 1073: 1, 254: 1, 451: 1, 568: 1, 224: 1, 481: 1, 302: 1, 167: 1, 145: 1, 243: 1, 779: 1, 351: 1, 131: 1, 425: 1, 264: 1, 161: 1, 119: 1, 283: 1, 288: 1, 124: 1, 362: 1, 266: 1, 506: 1, 201: 1, 361: 1, 404: 1, 305: 1, 130: 1, 1624: 1, 226: 1, 199: 1, 263: 1, 633: 1, 1514: 1, 2058: 1, 176: 1, 532: 1, 90: 1, 1857: 1, 587: 1, 815: 1, 311: 1, 429: 1, 282: 1, 309: 1, 433: 1, 890: 1, 503: 1, 570: 1, 442: 1, 389: 1, 761: 1, 1399: 1, 700: 1, 259: 1, 1354: 1, 298: 1, 214: 1, 599: 1, 261: 1, 1179: 1, 724: 1, 2181: 1, 502: 1, 463: 1, 211: 1, 218: 1, 1468: 1, 392: 1, 279: 1, 213: 1, 834: 1, 183: 1, 374: 1, 618: 1, 388: 1, 1825: 1, 1040: 1, 260: 1, 165: 1, 1863: 1, 2621: 1, 1608: 1, 287: 1, 172: 1, 443: 1, 395: 1, 103: 1, 4907: 1, 248: 1, 2425: 1, 418: 1, 2273: 1, 766: 1, 2145: 1, 924: 1, 785: 1, 1186: 1, 250: 1, 301: 1, 396: 1, 228: 1, 879: 1, 1307: 1, 306: 1, 967: 1, 726: 1, 5113: 1, 2278: 1, 223: 1, 337: 1, 377: 1, 535: 1, 629: 1, 487: 1, 242: 1, 580: 1, 219: 1, 432: 1, 1172: 1, 1613: 1, 406: 1, 1999: 1, 245: 1, 277: 1, 338: 1, 304: 1, 524: 1, 324: 1, 1628: 1, 399: 1, 811: 1, 1452: 1, 788: 1, 1123: 1, 373: 1, 355: 1, 894: 1, 906: 1, 402: 1, 438: 1, 1835: 1, 1142: 1, 538: 1, 1033: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l03dFmvMv7eX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8uwUOW1vLGW"
      },
      "source": [
        "def create_corpus_sienkiewicz():\n",
        "  corpus = {}\n",
        "  validate = []\n",
        "  sent_lengths = {}\n",
        "  with open('/content/drive/My Drive/nlp/korpus_sienkiewicza.txt', 'r', encoding = 'utf8') as file:\n",
        "   i=0\n",
        "   for line in file:\n",
        "    if line == '\\n': continue\n",
        "    i+=1\n",
        "    if i%5 == 0:\n",
        "      validate.append(line)\n",
        "      continue\n",
        "    words = line.split()\n",
        "    sen_len = 1\n",
        "    for word in words:\n",
        "      if word == '—':\n",
        "        continue\n",
        "      if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "        sen_len +=1\n",
        "      else:  \n",
        "        if sen_len in sent_lengths:\n",
        "          sent_lengths[sen_len] = sent_lengths[sen_len]+1\n",
        "        else:\n",
        "          sent_lengths[sen_len] = 1\n",
        "        sen_len = 0\n",
        "    for word in words:\n",
        "      if word in corpus:\n",
        "        num = corpus[word]\n",
        "        corpus[word] = num + 1\n",
        "      else:\n",
        "        corpus[word] = 1\n",
        "  return corpus, i, validate, sent_lengths\n",
        "\n",
        "corpus_sien, sien_size, val_sien, SL_sien = create_corpus_sienkiewicz()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVtg23DjvNKx"
      },
      "source": [
        "def create_corpus_prus():\n",
        "  corpus = {}\n",
        "  validate = []\n",
        "  sent_lengths = {}\n",
        "  with open('/content/drive/My Drive/nlp/korpus_prusa.txt', 'r', encoding = 'utf8') as file:\n",
        "   i=0\n",
        "   for line in file:\n",
        "    if line == '\\n': continue\n",
        "    i+=1\n",
        "    if i%5 == 0:\n",
        "      validate.append(line)\n",
        "      continue\n",
        "    words = line.split()\n",
        "    sen_len = 1\n",
        "    for word in words:\n",
        "      if word == '—':\n",
        "        continue\n",
        "      if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "        sen_len +=1\n",
        "      else:  \n",
        "        if sen_len in sent_lengths:\n",
        "          sent_lengths[sen_len] = sent_lengths[sen_len]+1\n",
        "        else:\n",
        "          sent_lengths[sen_len] = 1\n",
        "        sen_len = 0\n",
        "    for word in words:\n",
        "      if word in corpus:\n",
        "        num = corpus[word]\n",
        "        corpus[word] = num + 1\n",
        "      else:\n",
        "        corpus[word] = 1\n",
        "  return corpus,i, validate, sent_lengths\n",
        "\n",
        "corpus_prus, prus_size, val_prus, SL_prus = create_corpus_prus()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVTR2mrIwfRz",
        "outputId": "dfd827b5-8b11-40e9-8fd1-292f9ef56407"
      },
      "source": [
        "print(prus_size)\n",
        "print(len(corpus_prus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8323\n",
            "38446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkxiQ5E1wkb6"
      },
      "source": [
        "all_size = orz_size+sien_size+prus_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NVJ-cD908L-"
      },
      "source": [
        "def predict_author(sent, alpha, beta, gamma):\n",
        "#  beta = alpha\n",
        " # gamma = beta\n",
        "  preds = [0,0,0]\n",
        "  len_sent = len(sent)\n",
        "  words = sent#.split()\n",
        "  p = 0\n",
        "  if len_sent not in SL_orz:\n",
        "    SL_orz[len_sent] = 1\n",
        "  for word in words:\n",
        "    if word not in corpus_orz:\n",
        "      corpus_orz[word] = 1\n",
        "    p+= np.log( corpus_orz[word] / orz_size)\n",
        "  \n",
        "  preds[0] = (orz_size / all_size * SL_orz[len_sent] / orz_size)*alpha + (1-alpha)*orz_size / all_size * np.exp(p)\n",
        "\n",
        "  p=0\n",
        "  if len_sent not in SL_sien:\n",
        "    SL_sien[len_sent] = 1\n",
        "  for word in words:\n",
        "    if word not in corpus_sien:\n",
        "      corpus_sien[word] = 1\n",
        "    p+= np.log( corpus_sien[word] / sien_size)\n",
        "  preds[1] = (sien_size / all_size * SL_sien[len_sent] / sien_size)*beta + (1-beta)* sien_size / all_size * np.exp(p)\n",
        "  \n",
        "  p=0\n",
        "  if len_sent not in SL_prus:\n",
        "    SL_prus[len_sent] = 1\n",
        "  for word in words:\n",
        "    if word not in corpus_prus:\n",
        "      corpus_prus[word] = 1\n",
        "    p+= np.log( corpus_prus[word] / prus_size)\n",
        "  preds[2] = (prus_size / all_size * SL_prus[len_sent] / prus_size)*gamma  + (1-gamma)*(prus_size / all_size * np.exp(p))\n",
        "  \n",
        "  return  np.argmax(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dIM-8Ph3M7-",
        "outputId": "b0e1ad95-6b86-4561-90f4-711fe2c18e22"
      },
      "source": [
        "for a in np.arange(0.0, 1.0 ,0.1):\n",
        "  all_val_orz = 0\n",
        "  corr_pred_orz = 0\n",
        "  sent = []\n",
        "  for line in val_orz:\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "      if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "        sent.append(word)\n",
        "      else:\n",
        "        pred = predict_author(sent, a,a,a)\n",
        "        all_val_orz+=1\n",
        "        sent = []\n",
        "        if pred == 0:\n",
        "          corr_pred_orz+=1\n",
        "  print(a, corr_pred_orz / all_val_orz)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.6445953593661573\n",
            "0.1 0.46774193548387094\n",
            "0.2 0.47142048670062253\n",
            "0.30000000000000004 0.47198641765704585\n",
            "0.4 0.4722693831352575\n",
            "0.5 0.4722693831352575\n",
            "0.6000000000000001 0.4722693831352575\n",
            "0.7000000000000001 0.4722693831352575\n",
            "0.8 0.4722693831352575\n",
            "0.9 0.5766836445953594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KcUvySI3YJq",
        "outputId": "4ce83919-2d56-425d-81e2-d7dc00fe5ec8"
      },
      "source": [
        "for a in np.arange(0.0, 1.0 ,0.1):\n",
        "  all_val_sien = 0\n",
        "  corr_pred_sien = 0\n",
        "  sent = []\n",
        "  for line in val_sien:\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "      if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "        sent.append(word)\n",
        "      else:\n",
        "        pred = predict_author(sent, a,a,a)\n",
        "        all_val_sien+=1\n",
        "        sent = []\n",
        "        if pred == 1:\n",
        "          corr_pred_sien+=1\n",
        "  print(a, corr_pred_sien / all_val_sien)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.6942771084337349\n",
            "0.1 0.0007530120481927711\n",
            "0.2 0.0\n",
            "0.30000000000000004 0.0\n",
            "0.4 0.0\n",
            "0.5 0.0\n",
            "0.6000000000000001 0.0\n",
            "0.7000000000000001 0.0\n",
            "0.8 0.0\n",
            "0.9 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o37MHt4m3YMF",
        "outputId": "34cfdd94-0aea-43d8-dbb8-c62bc793a748"
      },
      "source": [
        "for a in np.arange(0.0, 1.0 ,0.1):\n",
        "  all_val_prus = 0\n",
        "  corr_pred_prus = 0\n",
        "  sent = []\n",
        "  for line in val_prus:\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "      if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "        sent.append(word)\n",
        "      else:\n",
        "        pred = predict_author(sent, a,a,a)\n",
        "        all_val_prus+=1\n",
        "        sent = []\n",
        "        if pred == 2:\n",
        "          corr_pred_prus+=1\n",
        "  print(a, corr_pred_prus / all_val_prus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.2436584494462308\n",
            "0.1 0.6059306895319757\n",
            "0.2 0.5959271168274384\n",
            "0.30000000000000004 0.5937834941050375\n",
            "0.4 0.5937834941050375\n",
            "0.5 0.5937834941050375\n",
            "0.6000000000000001 0.5937834941050375\n",
            "0.7000000000000001 0.5937834941050375\n",
            "0.8 0.5937834941050375\n",
            "0.9 0.5555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE8Fh2uNFVQ6",
        "outputId": "3f42c045-76a8-4470-a31b-744d79fe872c"
      },
      "source": [
        "max = 0\n",
        "params = []\n",
        "for a in np.arange(0, 0.01, 0.002):\n",
        "  for b in np.arange(0, 0.01, 0.002):\n",
        "    for c in np.arange(0, 0.01, 0.002):\n",
        "      all_val_orz = 0\n",
        "      corr_pred_orz = 0\n",
        "      sent = []\n",
        "      for line in val_orz:\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "          if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "            sent.append(word)\n",
        "          else:\n",
        "            pred = predict_author(sent, a,b,c)\n",
        "            all_val_orz+=1\n",
        "            sent = []\n",
        "            if pred == 0:\n",
        "              corr_pred_orz+=1\n",
        "      x = corr_pred_orz / all_val_orz\n",
        "\n",
        "      all_val_sien = 0\n",
        "      corr_pred_sien = 0\n",
        "      sent = []\n",
        "      for line in val_sien:\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "          if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "            sent.append(word)\n",
        "          else:\n",
        "            pred = predict_author(sent, a,b,c)\n",
        "            all_val_sien+=1\n",
        "            sent = []\n",
        "            if pred == 1:\n",
        "              corr_pred_sien+=1\n",
        "      y = corr_pred_sien / all_val_sien\n",
        "\n",
        "      all_val_prus = 0\n",
        "      corr_pred_prus = 0\n",
        "      sent = []\n",
        "      for line in val_prus:\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "          if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "            sent.append(word)\n",
        "          else:\n",
        "            pred = predict_author(sent, a,b,c)\n",
        "            all_val_prus+=1\n",
        "            sent = []\n",
        "            if pred == 2:\n",
        "              corr_pred_prus+=1\n",
        "      z = corr_pred_prus / all_val_prus\n",
        "      if x+y+z > max:\n",
        "        params = [a,b,c]\n",
        "        max = x+y+z\n",
        "print(params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fze8cRgZ3YO8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkoKP18M3YRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc933ce-1065-43ca-9321-399e86d634fe"
      },
      "source": [
        "def testy1(): \n",
        "  all_val_orz = 0\n",
        "  corr_pred_orz = 0  \n",
        "  for i in ['','1','3','5','7', '9', '11', '13', '15', '17', '19', '21']:\n",
        "    f = 'test_orzeszkowej' + i + '.txt'\n",
        "    with open('/content/drive/My Drive/nlp/testy1/' + f, 'r', encoding = 'utf8') as file:\n",
        "      sent = []\n",
        "      for line in file:\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "          if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "            sent.append(word)\n",
        "          else:\n",
        "            pred = predict_author(sent, 0, 0, 0)\n",
        "            all_val_orz+=1\n",
        "            sent = []\n",
        "            if pred == 0:\n",
        "              corr_pred_orz+=1\n",
        "  print( corr_pred_orz / all_val_orz)  \n",
        "        \n",
        "  \n",
        "testy1()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.38767650834403083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjatKFBWDbG2",
        "outputId": "c7ac22cd-3db2-4957-8f7c-99c4dca2e27b"
      },
      "source": [
        "def testy2(): \n",
        "  all_val = 0\n",
        "  corr_pred = 0  \n",
        "  for i in ['1','3','5','7', '9', '11', '13', '15', '17', '19', '21','23','25', '27', '29', '31']:\n",
        "    f = 'test_sienkiewicza' + i + '.txt'\n",
        "    with open('/content/drive/My Drive/nlp/testy1/' + f, 'r', encoding = 'utf8') as file:\n",
        "      sent = []\n",
        "      for line in file:\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "          if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "            sent.append(word)\n",
        "          else:\n",
        "            pred = predict_author(sent, 0, 0, 0)\n",
        "            all_val+=1\n",
        "            sent = []\n",
        "            if pred == 1:\n",
        "              corr_pred+=1\n",
        "  print( corr_pred / all_val)  \n",
        "        \n",
        "  \n",
        "testy2()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5920365535248042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC6FmMs3DdHZ",
        "outputId": "4fc1f259-2c9a-4f2d-cbf5-a200e0ee7eba"
      },
      "source": [
        "def testy3(): \n",
        "  all_val = 0\n",
        "  corr_pred = 0  \n",
        "  for i in ['0','2','4','6', '8', '10', '12', '14', '16', '18', '20','22','24', '26', '28', '30']:\n",
        "    f = 'test_prusa' + i + '.txt'\n",
        "    with open('/content/drive/My Drive/nlp/testy1/' + f, 'r', encoding = 'utf8') as file:\n",
        "      sent = []\n",
        "      for line in file:\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "          if word[-1:][0] != '.' and word[-1:][0] != '!' and word[-1:][0] != '?' and word[-1:][0] != ':' and word[-1:][0] != '“':\n",
        "            sent.append(word)\n",
        "          else:\n",
        "            pred = predict_author(sent, 0, 0, 0)\n",
        "            all_val+=1\n",
        "            sent = []\n",
        "            if pred == 1:\n",
        "              corr_pred+=1\n",
        "  print( corr_pred / all_val)  \n",
        "        \n",
        "  \n",
        "testy3()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5509727626459144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOXOM3W6FEu-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}