{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_p3_zad1-2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAvH03bHFumZ",
        "outputId": "b54aaf87-6c00-4df6-eee9-9bccf8d6b81b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/nlp'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/nlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKClg9wVLpQ6"
      },
      "source": [
        "import string\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6rI1agqKyU3"
      },
      "source": [
        "def rip_polish(word):\n",
        "  #word = word.lower()\n",
        "  #polish = []\n",
        "  word = word.replace('ą','a').replace('ć','c').replace('ę','e').replace('ł','l').replace('ż','z')\\\n",
        "    .replace('ź','z').replace('ń','n').replace('ó','o').replace('ś','s') \n",
        "  return word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n2iGsw6FxPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b274858-2cf2-4d2d-ef69-6b0d98b8992f"
      },
      "source": [
        "def create_corpus():\n",
        "  corpus = {}\n",
        " # big_corpus {}\n",
        "  with open('/content/drive/My Drive/nlp/polish_corpora.txt', 'r', encoding = 'utf8') as file:\n",
        "    for i, line in enumerate(file):\n",
        "      if i==1000000:\n",
        "        break\n",
        "  # #   print(line)\n",
        "      words = line.split()\n",
        "      for i in range(len(words)):\n",
        "\n",
        "        big = False\n",
        "        word_low = words[i].lower()\n",
        "        if i != 0:\n",
        "          if word_low[0] != words[i][0]:\n",
        "            big = True\n",
        "        if word_low in corpus:\n",
        "          num, b_cnt = corpus[word_low]\n",
        "          if big: b_cnt+=1\n",
        "          corpus[word_low] = (num + 1, b_cnt)\n",
        "        else:\n",
        "          if big:\n",
        "            corpus[word_low] = (1,1)\n",
        "          else: corpus[word_low] = (1,0) \n",
        "  print(len(corpus))\n",
        "  with open('/content/drive/My Drive/nlp/1grams', 'r', encoding = 'utf8') as file:\n",
        "    for i, line in enumerate(file):\n",
        "      words = line.split()\n",
        "      if words[1] not in corpus:\n",
        "        corpus[words[1]] = (int(words[0]), 0)\n",
        "       # print(corpus[words[1]])\n",
        "      #if i == 100:\n",
        "      #  break\n",
        "  print(len(corpus))\n",
        "  return corpus\n",
        "\n",
        "corpus = create_corpus()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "642272\n",
            "5575825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o20k5wp0Hg3_"
      },
      "source": [
        "def create_corpus_upper():\n",
        "  corpus_upper = {}\n",
        " # big_corpus {}\n",
        "  with open('/content/drive/My Drive/nlp/polish_corpora.txt', 'r', encoding = 'utf8') as file:\n",
        "    for i, line in enumerate(file):\n",
        "      if i==1000000:\n",
        "        break\n",
        "  # #   print(line)\n",
        "      words = line.split()\n",
        "      i=1\n",
        "      #for i in range(1, len(words)-1):\n",
        "      while i < len(words)-1:\n",
        "        new_upper_phrase = []\n",
        "        if words[i][0].isupper() and words[i+1][0].isupper():\n",
        "          new_upper_phrase.append(words[i])\n",
        "          new_upper_phrase.append(words[i+1])\n",
        "          j = i+2\n",
        "          while j<len(words) and words[j][0].isupper():\n",
        "            new_upper_phrase.append(words[j])\n",
        "            j+=1\n",
        "          new_upper_phrase = tuple(new_upper_phrase)\n",
        "          i+=len(new_upper_phrase)\n",
        "          if len(new_upper_phrase) > 5: continue\n",
        "          if new_upper_phrase in corpus_upper:\n",
        "            num = corpus_upper[new_upper_phrase]\n",
        "            corpus_upper[new_upper_phrase] = num + 1\n",
        "          else:\n",
        "            corpus_upper[new_upper_phrase] = 1\n",
        "        i+=1\n",
        "  return corpus_upper\n",
        "\n",
        "corpus_upper = create_corpus_upper()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpln6hcEK0Xe",
        "outputId": "8ab84459-8d78-431e-ae95-6bec5718de89"
      },
      "source": [
        "print(len(corpus_upper))\n",
        "k=0\n",
        "for l in corpus_upper:\n",
        "  if len(l)>k:\n",
        "    k=len(l)\n",
        "    print(l)\n",
        "  #if k==50:\n",
        "  #  break\n",
        "#  print(l, corpus_upper[l])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201928\n",
            "('Euroraty', 'Chcesz')\n",
            "('Heavy', 'Metal', 'Pages')\n",
            "('Przeciw', 'WZW', 'Typ', 'B')\n",
            "('BEZSTRESOWE', 'I', 'SPRAWNE', 'BADANIA', 'PSYCHOLOGICZNE')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRQ4IzZ1GKdK",
        "outputId": "9074cb99-2053-43c8-d6a3-65af659d422e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 7692997 w\n",
            "\n",
            "7692997 w\n",
            "\n",
            "5333210 i\n",
            "\n",
            "4235003 na\n",
            "\n",
            "4158902 z\n",
            "\n",
            "3981525 się\n",
            "\n",
            "3601719 nie\n",
            "\n",
            "3102150 -\n",
            "\n",
            "2904114 do\n",
            "\n",
            "2205896 że\n",
            "\n",
            "2171877 to\n",
            "\n",
            "1731304 o\n",
            "\n",
            "1728527 jest\n",
            "\n",
            "1425793 a\n",
            "\n",
            "1069230 ■\n",
            "\n",
            "1003027 jak\n",
            "\n",
            " 983395 po\n",
            "\n",
            " 912660 od\n",
            "\n",
            " 877522 ale\n",
            "\n",
            " 847373 za\n",
            "\n",
            " 775006 przez\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6RNHnGopzCk"
      },
      "source": [
        "word = 'ania'\n",
        "if word[0].isupper():\n",
        "  print(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XldWUXpFsbxg",
        "outputId": "77152882-aec6-4616-8867-0b91ffe21a1a"
      },
      "source": [
        "k=0\n",
        "for word in corpus:\n",
        "  print(word, corpus[word])\n",
        "  k+=1\n",
        "  if k==10:break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "system (4714, 228)\n",
            "euroraty (1, 1)\n",
            "chcesz (663, 20)\n",
            "kupować (162, 0)\n",
            "więcej (5846, 67)\n",
            "niż (9776, 8)\n",
            "gdzie (11654, 70)\n",
            "indziej (160, 0)\n",
            "? (37854, 0)\n",
            "parlament (688, 92)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVW0N92MM9nD"
      },
      "source": [
        "def create_corpus_themes(corpus):\n",
        "  corpus_themes = {}\n",
        "  for word in corpus:\n",
        "    theme = rip_polish(word)\n",
        "    if theme in corpus_themes:\n",
        "      corpus_themes[theme].append((word, corpus[word][0], corpus[word][1]))\n",
        "    else:\n",
        "      corpus_themes[theme] = [(word, corpus[word][0], corpus[word][1])] \n",
        "  return corpus_themes\n",
        "corpus_themes = create_corpus_themes(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyPNIKcnXbcq"
      },
      "source": [
        "def create_test_corpus():\n",
        "  corpus = []\n",
        "  with open('/content/drive/My Drive/nlp/polish_corpora.txt', 'r', encoding = 'utf8') as file:\n",
        "    for i, line in enumerate(file):\n",
        "      if i < 1000000:\n",
        "        continue\n",
        "      if i == 1200000: break\n",
        "\n",
        "      corpus.append(line)\n",
        "  return corpus\n",
        "\n",
        "corpus_test = create_test_corpus()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6o6y1aNKPNj"
      },
      "source": [
        "k=0\n",
        "for i in corpus_themes:\n",
        "  k+=1\n",
        "  if k==1000: break\n",
        "  for j in corpus_themes[i]:\n",
        "    if j[2] > j[1]*0.4:\n",
        "      print(i, corpus_themes[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie5jGCzcF70K",
        "outputId": "0bb1595a-1bf7-43a0-adb3-2d62223fce48"
      },
      "source": [
        "k=0\n",
        "for i in corpus_test:\n",
        "  k+=1\n",
        "  if k==10: break\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Swój pierwszy turniej rangi ATP World Tour wygrał w 1997 roku w Orlando w grze podwójnej .\n",
            "\n",
            "Jedną z pierwszych wizyt w trakcie pełnienia urzędu ministra spraw zagranicznych odbywałam również w Irlandii i była to okazja do istotnych konsultacji .\n",
            "\n",
            "Gdyby pracy nad tą ustawą poświęcono więcej czasu i byłaby większa możliwość przeprowadzenia szerszych konsultacji , to zapewne przyjęte rozwiązania byłyby lepsze .\n",
            "\n",
            "Wzniesienie zbudowane jest z waryscyjskich granitów porfirowatych .\n",
            "\n",
            "Postanowili na nim zainstalować huśtawkę ze mną w środku .\n",
            "\n",
            "W 1999 na podstawie książki powstał film o tym samym tytule .\n",
            "\n",
            "Mistrzostwa Europy w łyżwiarstwie szybkim rozgrywane są wyłącznie w wieloboju .\n",
            "\n",
            "Proszę bardzo pana marszałka Wojciechowskiego o prowadzenie obrad .\n",
            "\n",
            "Na jesieni 1980 został członkiem zespołu przygotowującego do druku Tygodnika Solidarność ( szefem zespołu był Jerzy Zieleński ) .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Yp_Uc7QC6v",
        "outputId": "d045e5b6-f635-4444-8d3e-ada8d50107ba"
      },
      "source": [
        "corpus_themes['ania']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ania', 70, 52), ('anią', 6, 6)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRFnjX_pod1t"
      },
      "source": [
        "### zadanie 1 podejście tylko unigramy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF8FrzUtgpWv"
      },
      "source": [
        "def normalization_dict(values, val_id):\n",
        "  frequency = []\n",
        "  for x in values:\n",
        "    frequency.append((x[val_id]))\n",
        "  sum_all = sum(frequency)\n",
        "  return [i/sum_all for i in frequency]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQSol0EPXR6O"
      },
      "source": [
        "def reverse_tokenize(sent): # znaki diakrytyczne tylko\n",
        "  sent = sent.split()\n",
        "  corr_phrase = sent\n",
        "  token_sen = sent\n",
        "\n",
        "  phrase_reversed = []\n",
        "  for i in range(len(sent)):\n",
        "    token_sen[i] = rip_polish(sent[i].lower())\n",
        "    \n",
        "  for i in range(len(corr_phrase)):\n",
        "    \n",
        "    curr_word = token_sen[i]\n",
        "    if token_sen[i] in corpus_themes:\n",
        "      num_inst = 0\n",
        "      for word_theme in corpus_themes[curr_word]:\n",
        "        if word_theme[1] > num_inst:\n",
        "          num_inst = word_theme[1]\n",
        "          word_to_add = word_theme\n",
        "\n",
        "      to_add = word_to_add[0]\n",
        "      if word_to_add[2] > 0.5*word_to_add[1]:\n",
        "        to_add =  word_to_add[0][0].upper() + word_to_add[0][1:]\n",
        "      if i==0:\n",
        "        to_add =  word_to_add[0][0].upper() + word_to_add[0][1:]\n",
        "      phrase_reversed.append(to_add)\n",
        "    else:\n",
        "      phrase_reversed.append(curr_word)\n",
        "  return phrase_reversed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UlsxXW5GK0h"
      },
      "source": [
        "def test_reverse_tokenize(reverse_f, corp_test, sent_start, sent_end, strip_punct=False):\n",
        "  score_low, score_full, all = 0,0, 0\n",
        "  num = 0\n",
        "  for sent in corp_test:\n",
        "    #print(sent.split())\n",
        "    if num < sent_start:\n",
        "      num+=1\n",
        "      continue\n",
        "    if num == sent_end:\n",
        "      break\n",
        "    if strip_punct:\n",
        "      sent = sent.translate(str.maketrans('', '', string.punctuation))\n",
        "    rev = reverse_f(sent)\n",
        "    sent_full = sent.split()\n",
        "    sent_low = sent.lower().split()\n",
        "    for i in range(len(rev)):\n",
        "      if sent_full[i] == rev[i]:\n",
        "        score_full += 1\n",
        "      if sent_low[i] == rev[i].lower():\n",
        "        score_low += 1  \n",
        "      all+=1\n",
        "    #print(sent)\n",
        "    #print(rev)\n",
        "    #if num_sent == 0 :\n",
        "    #  break\n",
        "    num+=1\n",
        "  return score_low/all, score_full/all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5EPC2qG7RqP",
        "outputId": "8837f47a-5ca9-4afa-9ecf-2fe7e3419d2f"
      },
      "source": [
        "score_low, score_full = test_reverse_tokenize(reverse_tokenize, corpus_test, 0, 200000, strip_punct=False)\n",
        "avg = np.sqrt(score_low*score_full)\n",
        "print(score_low, score_full, avg)#zmiana korpusu na nkjp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.976634029092797 0.9346018264483545 0.9553868051013388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAUvcJleQeYB",
        "outputId": "c3a7647b-d29a-4d5a-d491-a7984fe3de55"
      },
      "source": [
        "score_low, score_full = test_reverse_tokenize(reverse_tokenize, corpus_test, 0, 200000, strip_punct=False)\n",
        "avg = np.sqrt(score_low*score_full)\n",
        "print(score_low, score_full, avg)# opt wielkich liter, tylko max"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9754183196664928 0.9334994437038222 0.9542287245661745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm7G5I1uQY0M",
        "outputId": "94671cd4-e610-4c6b-875d-009da8f8ba11"
      },
      "source": [
        "for i in range(1,20):\n",
        "  score_low, score_full = test_reverse_tokenize(reverse_tokenize,corpus_test, (i-1)*10000, i*10000, strip_punct=False)\n",
        "  avg = np.sqrt(score_low*score_full)\n",
        "  print(i, score_low, score_full, avg)# proste wielkie litery,"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0.9672049981114162 0.9250232244760456 0.9458790018191385\n",
            "2 0.9675364046491075 0.9248476502687316 0.9459512515923766\n",
            "3 0.9678820988438572 0.927236691652903 0.9473414354086104\n",
            "4 0.9677835444195045 0.9254258117592095 0.9463677256762432\n",
            "5 0.9667690977315895 0.926146687461717 0.9462399259196711\n",
            "6 0.96647031475909 0.9261253620930125 0.9460828030402043\n",
            "7 0.9672739212296264 0.9257853181545344 0.9463022745973686\n",
            "8 0.9671768177006898 0.9254971543696916 0.9461074952426507\n",
            "9 0.9667829678154372 0.9251841152296862 0.945754854440333\n",
            "10 0.9670761745941894 0.9269311384116397 0.9467909058748746\n",
            "11 0.9676993668813998 0.9259145466175752 0.9465764208705527\n",
            "12 0.9665822396193108 0.9254483587893673 0.9457917039658584\n",
            "13 0.9682462114587298 0.9259575518770383 0.9468658255405265\n",
            "14 0.9663125466957332 0.9231426612218162 0.9444809875951605\n",
            "15 0.9672442185150713 0.9240147695077172 0.9453824324731636\n",
            "16 0.967490366383265 0.9266570840214489 0.9468536326864673\n",
            "17 0.9671371767361924 0.925747205922732 0.9462159051228898\n",
            "18 0.9669724582673858 0.9253858249970548 0.9459506361556056\n",
            "19 0.9676195720338335 0.9267552781984021 0.946967024595067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC__OLQmQ_dT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htO6NWKwop87"
      },
      "source": [
        "### zadanie 2 - dodanie bigramów"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY_Jy_5hIJWw"
      },
      "source": [
        "def create_bigrams(corpus):\n",
        "  bigrams_dict = {}\n",
        "  with open('/content/drive/My Drive/nlp/2grams', 'r', encoding = 'utf8') as file: #using nkjp bigrams - as in task description\n",
        "    for i, line in enumerate(file):\n",
        "      #if i >= 20000:\n",
        "      #  print(i)\n",
        "      #  break\n",
        "   #   print(line)\n",
        "      words = line.split()\n",
        "      how_many, word1, word2 = int(words[0]), words[1], words[2]  #cast to int\n",
        "      if how_many < 2:\n",
        "        continue\n",
        "      \n",
        "      ripped1 = rip_polish(word1)#.lower()\n",
        "      ripped2 = rip_polish(word2)#.lower()\n",
        "     # if ripped1 not in corpus:\n",
        "     #   corpus[ripped1] = (int(how_many), 0)\n",
        "     # if ripped2 not in corpus:\n",
        "     #   corpus[ripped2] = (int(how_many), 0)  \n",
        "      if (ripped1, ripped2) in bigrams_dict:\n",
        "        bigrams_dict[ (ripped1, ripped2) ].append((word1, word2, how_many))\n",
        "      else:\n",
        "        bigrams_dict[(ripped1, ripped2)] = [(word1, word2, how_many)]\n",
        "  return corpus, bigrams_dict\n",
        "\n",
        "corpus, bigrams_themes = create_bigrams(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K59Gkc-fk_Qk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde13af1-3a5f-4b3e-9a83-dc3309cfae2e"
      },
      "source": [
        "len(bigrams_themes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16611767"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEU7ba64hOdV",
        "outputId": "d6afe642-ec6e-4cb6-800f-c44ce93d9bf8"
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5982878"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AoZyJKPRfOH",
        "outputId": "330c80b2-5bb0-4713-f880-54c4ff8081c9"
      },
      "source": [
        "len(bigrams_themes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17894055"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FD_tUCmSU9b"
      },
      "source": [
        "def reverse_tokenize_bigrams(sent): \n",
        "  sent = sent.split()\n",
        "  corr_phrase = sent\n",
        "  token_sen = sent\n",
        "  for i in range(0,len(sent)):\n",
        "    token_sen[i] = rip_polish(sent[i].lower())\n",
        "\n",
        "  phrase_reversed = []\n",
        "  curr_word = token_sen[0]\n",
        "  if token_sen[0] in corpus_themes:\n",
        "    num_inst = 0\n",
        "    for word_theme in corpus_themes[curr_word]: #choose always max  value\n",
        "      if word_theme[1] > num_inst:\n",
        "        num_inst = word_theme[1]\n",
        "        word_to_add = word_theme\n",
        "    to_add =  word_to_add[0][0].upper() + word_to_add[0][1:]\n",
        "    phrase_reversed.append(to_add)\n",
        "  else:\n",
        "    curr_word = curr_word[0].upper()+curr_word[1:]\n",
        "    if len(curr_word)<=4:\n",
        "      phrase_reversed.append(curr_word.upper())\n",
        "    else:\n",
        "      phrase_reversed.append(curr_word)\n",
        "\n",
        "  for i in range(1,len(corr_phrase)):\n",
        "    prev_word = phrase_reversed[-1:][0]\n",
        "    curr_word_theme = token_sen[i]\n",
        "    prev_word_theme = token_sen[i-1]\n",
        "    \n",
        "    bigram_add = False\n",
        "    correct_word_prev = []\n",
        "    if (prev_word_theme, curr_word_theme) in bigrams_themes:\n",
        "      for word_pair in bigrams_themes[(prev_word_theme, curr_word_theme)]:\n",
        "       # print(word_pair)\n",
        "        if 1:#word_pair[0] == phrase_reversed[-1:][0]:\n",
        "          correct_word_prev.append(word_pair)\n",
        "      if len(correct_word_prev) > 0:\n",
        "        num_inst = 0\n",
        "        for word_pairs in correct_word_prev:\n",
        "          if word_pairs[2] > num_inst:\n",
        "\n",
        "            num_inst = word_pairs[2]\n",
        "            word_to_add = word_pairs\n",
        "\n",
        "        to_add = word_to_add[1]\n",
        "        #if word_to_add[2] > 0:\n",
        "        if num_inst > 0:\n",
        "          if word_to_add[1] in corpus:\n",
        "            check_upper = corpus[word_to_add[1]]\n",
        "            if check_upper[1]*1.84 > check_upper[0]:\n",
        "              to_add = word_to_add[1][0].upper() + word_to_add[1][1:]\n",
        "  \n",
        "          phrase_reversed.append(to_add)\n",
        "          bigram_add = True\n",
        "        else:\n",
        "          bigram_add =  False\n",
        "      else:\n",
        "        bigram_add == False\n",
        "    \n",
        "    if bigram_add == False:\n",
        "      if curr_word_theme in corpus_themes:\n",
        "        num_inst = 0\n",
        "        for word_theme in corpus_themes[curr_word_theme]: #choose always max  value\n",
        "          if word_theme[1] > num_inst:\n",
        "            num_inst = word_theme[1]\n",
        "            word_to_add = word_theme\n",
        "\n",
        "        to_add = word_to_add[0]\n",
        "        if word_to_add[2]*2.1 > word_to_add[1]:\n",
        "          if word_to_add[0].isupper():\n",
        "            to_add = word_to_add[0].upper()\n",
        "          else:\n",
        "            to_add =  word_to_add[0][0].upper() + word_to_add[0][1:]\n",
        "        phrase_reversed.append(to_add)\n",
        "      else:\n",
        "        if len(curr_word_theme)<=4:\n",
        "          phrase_reversed.append(curr_word_theme.upper())\n",
        "        else:\n",
        "          phrase_reversed.append(curr_word_theme)\n",
        "  '''\n",
        "  for i in range(0):#range(len(phrase_reversed)-1):\n",
        "    upper_check = []\n",
        "    k=i\n",
        "    while len(upper_check)<5 and k< len(phrase_reversed) :\n",
        "      upper_check.append(phrase_reversed[k][0].upper() + phrase_reversed[k][1:])\n",
        "      k+=1\n",
        "    while len(upper_check)>1:\n",
        "      upper_check = tuple(upper_check)\n",
        "      if upper_check in corpus_upper and corpus_upper[upper_check] > 0:\n",
        "        to_upper = len(upper_check)\n",
        "        w = i\n",
        "        while to_upper:\n",
        "          phrase_reversed[w] = phrase_reversed[w][0].upper() + phrase_reversed[w][1:]\n",
        "          w+=1\n",
        "          to_upper-=1\n",
        "        break\n",
        "      else:\n",
        "        upper_check = list(upper_check)\n",
        "        upper_check = upper_check[:-1]\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  for i in range(len(phrase_reversed)-1):\n",
        "    first = phrase_reversed[i][0].upper() + phrase_reversed[i][1:]\n",
        "    second = phrase_reversed[i+1][0].upper() + phrase_reversed[i+1][1:]\n",
        "    upper_check = tuple([first,second])\n",
        "    if upper_check in corpus_upper and corpus_upper[upper_check] > 40:\n",
        "      to_upper = 2\n",
        "      j = i + 2\n",
        "      while j < len(phrase_reversed):\n",
        "        next = phrase_reversed[j][0].upper() + phrase_reversed[j][1:]\n",
        "        upper_check = list(upper_check)\n",
        "        upper_check.append(next)\n",
        "        upper_check = tuple(upper_check)\n",
        "        if upper_check in corpus_upper and corpus_upper[upper_check] > 30:\n",
        "          to_upper +=1\n",
        "          j+=1\n",
        "        else:\n",
        "          break\n",
        "      k = i\n",
        "      while to_upper:\n",
        "        phrase_reversed[k] = phrase_reversed[k][0].upper() + phrase_reversed[k][1:]\n",
        "        k+=1\n",
        "        to_upper-=1\n",
        "  '''\n",
        "\n",
        "\n",
        "  return phrase_reversed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiV75unGIKjm",
        "outputId": "6f8c21f0-ad30-4280-b95c-b48336e930d8"
      },
      "source": [
        "score_low, score_full = test_reverse_tokenize(reverse_tokenize_bigrams, corpus_test, 0, 200000, strip_punct=False)\n",
        "avg = np.sqrt(score_low*score_full)\n",
        "print(score_low, score_full, avg)#score geometryczny 4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.983349400708598 0.9411369984305276 0.9620116960782483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWHZUvtGTpi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19f80e7-8c21-47c0-9110-df583df9502d"
      },
      "source": [
        "score_low, score_full = test_reverse_tokenize(reverse_tokenize_bigrams, corpus_test, 0, 200000, strip_punct=False)\n",
        "avg = np.sqrt(score_low*score_full)\n",
        "print(score_low, score_full, avg)#score geometryczny 4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.983349400708598 0.9406385141748963 0.9617568919416748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQdrGI3WTpoA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijoy0MIyTptK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJSAHANFTWEG",
        "outputId": "eb2c3792-23b9-41c5-9aff-be19029046e1"
      },
      "source": [
        "score_low, score_full = test_reverse_tokenize(reverse_tokenize_bigrams, corpus_test, 0, 200000, strip_punct=False)\n",
        "avg = np.sqrt(score_low*score_full)\n",
        "print(score_low, score_full, avg)# 4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.983349400708598 0.9411357222291562 0.9620110438240791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glJdpQwcTWPQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrfrf9UQO-Go",
        "outputId": "ee20e2ba-bed1-4ec8-fbda-3f4ce88e8fd9"
      },
      "source": [
        "score_low, score_full = test_reverse_tokenize(reverse_tokenize_bigrams, corpus_test, 0, 200000, strip_punct=False)\n",
        "avg = np.sqrt(score_low*score_full)\n",
        "print(score_low, score_full, avg)#"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.982756222311216 0.9410754855244307 0.9616900691302177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMNUxUX38gkN",
        "outputId": "720c6e1e-82da-4bf3-9df5-89279a48e878"
      },
      "source": [
        "score_low, score_full = test_reverse_tokenize(reverse_tokenize_bigrams, corpus_test, 0, 200000, strip_punct=False)\n",
        "avg = np.sqrt(score_low*score_full)\n",
        "print(score_low, score_full, avg)#"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9827500965446337 0.9408983487740937 0.9615965594241834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7BwWU-utbsS",
        "outputId": "ce0bac6c-abac-4b1b-e8d9-9ebd79049dce"
      },
      "source": [
        "score_low, score_full = test_reverse_tokenize(reverse_tokenize_bigrams, corpus_test, 0, 200000, strip_punct=False)\n",
        "avg = np.sqrt(score_low*score_full)\n",
        "print(score_low, score_full, avg)#"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9754262321149949 0.9340400426047066 0.9545088576867363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beXhvpd-hQxS",
        "outputId": "c103e233-7a1d-46b9-9050-bc91b41f1a54"
      },
      "source": [
        "score_low, score_full = test_reverse_tokenize(reverse_tokenize_bigrams, corpus_test, 0, 200000, strip_punct=False)\n",
        "avg = np.sqrt(score_low*score_full)\n",
        "print(score_low, score_full, avg)#score bigramy, full match na bigramach"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9672779415994938 0.926188851768445 0.9465104574546338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUG4FEZRHbzV",
        "outputId": "15420faa-5ddf-45c7-ce65-403f9065f970"
      },
      "source": [
        "kk=0\n",
        "for k in bigrams_themes:\n",
        "  print(k, bigrams_themes[k])\n",
        "  kk+=1\n",
        "  if kk==10:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('masz', 'identyczny') [('masz', 'identyczny', 2)]\n",
            "('rozdrobniona', 'siec') [('rozdrobniona', 'sieć', 11)]\n",
            "('filmie', 'wraz') [('filmie', 'wraz', 2)]\n",
            "('swiadectwem', ',') [('świadectwem', ',', 87)]\n",
            "('swiadectwem', '-') [('świadectwem', '-', 3)]\n",
            "('swiadectwem', '.') [('świadectwem', '.', 41)]\n",
            "('i', '54,6') [('i', '54,6', 4)]\n",
            "('i', '54,4') [('i', '54,4', 3)]\n",
            "('nastapilo', 'przedawnienie') [('nastąpiło', 'przedawnienie', 32)]\n",
            "('podzielaja', 'poglad') [('podzielają', 'pogląd', 32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK64yw1IU0Um"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtrDIit-vJeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e41f1c-6ff6-4f74-d768-cac415fa9b1f"
      },
      "source": [
        "85/95"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8947368421052632"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7OVhCylVehZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873d66b4-bdd4-431a-dfa1-a0aa1b6890e6"
      },
      "source": [
        "135/150\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMfyJpstVhSj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}