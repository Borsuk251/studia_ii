{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bu7QPt2ziJw",
        "outputId": "5e74f094-806c-411b-fdc1-d20c2809e281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 24 07:30:12 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0    25W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load drive data"
      ],
      "metadata": {
        "id": "egXgcvxP0SiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/boty/project'"
      ],
      "metadata": {
        "id": "Z5Wk4TFczxk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install packages, imports"
      ],
      "metadata": {
        "id": "aJbd7E-r0Vt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install import-ipynb\n",
        "import import_ipynb\n",
        "\n",
        "!pip install transformers\n",
        "!pip install sacremoses\n",
        "!pip install textdistance\n",
        "\n",
        "!pip install deepl\n",
        "!pip install fasttext\n",
        "!pip install easynmt"
      ],
      "metadata": {
        "id": "1ByiwV2wzxia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load herbert\n",
        "\n",
        "def load_herbert():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-large-cased\")\n",
        "    model = AutoModel.from_pretrained(\"allegro/herbert-large-cased\")\n",
        "    return tokenizer, model\n",
        "\n",
        "def load_polbert():\n",
        "    model = BertForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")\n",
        "    return tokenizer, model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ECe0fpCfEs03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## proper code"
      ],
      "metadata": {
        "id": "tCzkl5mT8QTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel, BertForMaskedLM, BertTokenizer, pipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
        "import torch\n",
        "# from easynmt import EasyNMT\n",
        "\n",
        "import textdistance\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from ast import literal_eval\n",
        "import json\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim"
      ],
      "metadata": {
        "id": "DynfUR6HpKQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tools import DeepL, CONFIG, LanguageIdentification, M2M_translator\n",
        "from scraping import Courses, StudyRules\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5IOs7EWkAcU",
        "outputId": "a18044c8-9cae-4d96-e58d-0026e40f7d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from scraping.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class LanguageModel:\n",
        "\n",
        "    def __init__(self, model_command, tokenizer_command):\n",
        "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model = model_command.to(self.device)\n",
        "        self.tokenizer = tokenizer_command\n",
        "\n",
        "    def encode_input(self, prompt):\n",
        "        # addition of eos token\n",
        "        input_ids = self.tokenizer.encode(prompt + self.tokenizer.eos_token, return_tensors=\"pt\").to(self.device)\n",
        "        # input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "        return input_ids\n",
        "\n",
        "    def generate_output(self, prompt):\n",
        "        \"\"\"\n",
        "        generate answer from the model with sampling\n",
        "        \"\"\"\n",
        "        input_ids = self.encode_input(prompt)\n",
        "        # sampling to mimic more human behaviour\n",
        "        output = self.model.generate(\n",
        "            input_ids,\n",
        "            # max_length=200,\n",
        "            max_new_tokens=70,\n",
        "            do_sample=True,\n",
        "            top_k=15,\n",
        "            temperature=0.75,\n",
        "            pad_token_id=self.tokenizer.eos_token_id,\n",
        "\n",
        "        )\n",
        "        return self.tokenizer.batch_decode(output, skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "NTjnpbFt6Epi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2Vec_class:\n",
        "    def __init__(self):\n",
        "        self.model = api.load('word2vec-google-news-300')\n",
        "\n",
        "# word2vec = Word2Vec_class()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PWTTFUZVk8N",
        "outputId": "61cbb93a-4d45-4659-f897-c7cc003ed8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://zapisy.ii.uni.wroc.pl/courses/semester/347'\n",
        "courses = Courses(URL)\n",
        "courses.get_courses_person('Jan Otop')\n",
        "\n",
        "# model_name = \"microsoft/DialoGPT-small\"\n",
        "# LM = LanguageModel(tokenizer_command=AutoTokenizer.from_pretrained(model_name), \n",
        "#                    model_command=AutoModelForCausalLM.from_pretrained(model_name))\n",
        "LM2 = LanguageModel(model_command=BlenderbotForConditionalGeneration.from_pretrained(\"facebook/blenderbot-400M-distill\"),\n",
        "                    tokenizer_command=BlenderbotTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\"))\n",
        "\n",
        "LANGUAGE = LanguageIdentification()\n",
        "\n",
        "config = CONFIG()\n",
        "\n",
        "# chooose translator\n",
        "translator = DeepL(config.config['DEEPL_KEY'])\n",
        "m2m = M2M_translator()"
      ],
      "metadata": {
        "id": "UFVOwG1oVlCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LM2.generate_output('How are you today?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCeYXXMi0X9J",
        "outputId": "42e1c047-27d3-44e1-f635-6ed688841313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" I'm doing well, how are you? Do you have any plans for the weekend? \"]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LM2.generate_output('How are you?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix3is7Yv-b7c",
        "outputId": "e42a74c1-ce06-44aa-c3e1-31ba1acf468b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" I'm doing well. How about yourself? What are you up to today? I'm watching TV.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CourseRecommender:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.courses_english = self.read_to_json()\n",
        "\n",
        "\n",
        "        self.emb_dict = self.create_embeddings(word2vec.model)\n",
        "\n",
        "    def translate_descriptions(self, translator):\n",
        "        \"\"\"\n",
        "        high usage of deepl API\n",
        "        \"\"\"\n",
        "        courses_english = {}\n",
        "        for course in courses.courses:\n",
        "            current_lang = LANGUAGE.predict_en_pl(course['description'])\n",
        "            if current_lang != 'en':\n",
        "                en_descr = translator.translate(course['description'])\n",
        "                courses_english[course['name']] = en_descr\n",
        "            else:\n",
        "                courses_english[course['name']] = course['description']\n",
        "        return courses_english\n",
        "\n",
        "    def process_stars(self, courses_english):\n",
        "        for key, value in courses_english.items():\n",
        "            if value[:2] == '**':\n",
        "                i = 2\n",
        "                while value[i:i+2] != '**':\n",
        "                    i+=1\n",
        "                print(value[:i+2])\n",
        "                courses_english[key] = value[i+2:]\n",
        "        return courses_english\n",
        "\n",
        "    def save_to_json(self, courses_english):\n",
        "        with open('courses_english.json', 'w') as fh:\n",
        "            json.dump(courses_english, fh)\n",
        "\n",
        "    def read_to_json(self):\n",
        "        with open('courses_english.json', 'r') as fh:\n",
        "            courses_english = json.load(fh)\n",
        "        return courses_english\n",
        "\n",
        "    def create_embeddings(self, word2vec_model):\n",
        "        emb_dict = {}\n",
        "        for key, value in self.courses_english.items():\n",
        "\n",
        "            tokens = value.split()\n",
        "            emb = np.zeros((len(tokens), 300))\n",
        "            for i, token in enumerate(tokens):\n",
        "                token = token.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "                if token in word2vec_model:\n",
        "                    emb[i] = word2vec_model[token]\n",
        "\n",
        "            emb = emb.mean(axis=0)\n",
        "            emb_dict[key] = emb\n",
        "            # print(emb.shape)\n",
        "\n",
        "        import pickle\n",
        "        with open('emb_courses.pkl', 'wb') as fh:\n",
        "            pickle.dump(emb_dict, fh)\n",
        "\n",
        "        return emb_dict\n",
        "\n",
        "    def find_best_course(self, course_in):\n",
        "        cossim = {}\n",
        "        for course_name in self.emb_dict.keys():\n",
        "            if course_name != course_in:\n",
        "                res = cosine_similarity(recommender.emb_dict[course_name].reshape(1, -1), recommender.emb_dict[course_in].reshape(1, -1))\n",
        "                cossim[course_name] = res\n",
        "\n",
        "        res = sorted(cossim.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return [i[0] for i in res[:3]]\n",
        "\n",
        "recommender = CourseRecommender()\n",
        "recommender.find_best_course('Projekt: Deep Learning')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB8iYxDqiVJ0",
        "outputId": "8402b2d6-42b6-46c5-c532-15eea7925a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Neural Networks and Natural Language Processing',\n",
              " 'Advanced Data Mining',\n",
              " 'Sieci komputerowe']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rule based system\n",
        "\n",
        "QUESTION_DEGREE = 'Powiedz proszę, jaki stopień studiów Cię interesuje'\n",
        "\n",
        "\n",
        "class RuleSystem:\n",
        "    \"\"\"\n",
        "    rule based system working in Polish\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def check_if_contains(self, text: str, forms: list, error_size=2) -> bool:\n",
        "        for f in forms:\n",
        "            if f in text:\n",
        "                return f\n",
        "            elif textdistance.levenshtein.distance(' '.join(text.split()[:len(f.split())]), f) <= error_size:\n",
        "                return f\n",
        "        return ''\n",
        "\n",
        "    def find_closest(self, text, candidates, surnames=False):\n",
        "\n",
        "        # dist_dict = {}\n",
        "        smallest_dist = 5\n",
        "        closest = None\n",
        "        for c in candidates:\n",
        "            distance = textdistance.levenshtein.distance(text.lower(), c.lower())\n",
        "            # print(distance, c)\n",
        "            if distance < smallest_dist:\n",
        "                smallest_dist = distance\n",
        "                closest = c\n",
        "        if surnames:\n",
        "            if closest == None:\n",
        "                # go through surnames only\n",
        "                for c in candidates:\n",
        "                    distance = textdistance.levenshtein.distance(text, c.split()[1])\n",
        "                    if distance < smallest_dist:\n",
        "                        smallest_dist = distance\n",
        "                        closest = c\n",
        "        return closest\n",
        "\n",
        "    def basic_links(self, prompt):\n",
        "\n",
        "        if prompt == 'zapisy':\n",
        "            to_print = f\"Zapisywać się na przedmioty i nie tylko można na stronie:\\nhttps://zapisy.ii.uni.wroc.pl/'\"\n",
        "        elif prompt == 'ii':\n",
        "            to_print = f\"Strona główna Instytutu Informatyki:\\nhttps://ii.uni.wroc.pl/'\"\n",
        "        \n",
        "        return to_print\n",
        "\n",
        "    def convert_type(self, type_course):\n",
        "        mapping_abbreviations = {'sem': 'Seminarium', 'i2z': 'I2.Z - zastosowania inf.', 'i2t': 'I2.T - teoria inf.', \n",
        "                        'o1': 'Obowiązkowy 1', 'o2': 'Obowiązkowy 2', 'o3': 'Obowiązkowy 3', \n",
        "                        'human': 'Humanistyczno-społeczny', 'i1': 'Informatyczny 1', 'kinż': 'Kurs inżynierski',\n",
        "                        'k1': 'K1 - kurs podstawowy', 'k2': 'K2 - kurs zaawansowany', 'iinź': 'Informatyczny inż.',\n",
        "                        'inne': 'Inne'}\n",
        "        type_course = type_course.lower()\n",
        "        if type_course in mapping_abbreviations:\n",
        "            return mapping_abbreviations[type_course]\n",
        "        return type_course\n",
        "\n",
        "    def choose_rule(self, prompt):\n",
        "        prompt = prompt.translate(str.maketrans('', '', string.punctuation))\n",
        "        prompt_lower = prompt.lower()\n",
        "\n",
        "        basic_link = ['zapisy', 'jaka jest strona zapisów', 'gdzie mogę się zapisać', 'gdzie mogę zagłosować',\n",
        "                      'na jakiejs stronie mogę się zapisać', 'na jakiejs stronie mogę zagłosować',\n",
        "                      'gdzie mogę sprawdzić swój plan']\n",
        "\n",
        "        check = self.check_if_contains(prompt_lower, basic_link)\n",
        "        if check:\n",
        "            to_print = self.basic_links('zapisy')\n",
        "            return to_print\n",
        "\n",
        "        # kursy prowadzacego\n",
        "        courses_conduct_forms = ['jakie zajęcia prowadzi', 'co prowadzi', 'jakie kursy prowadzi', 'co wykłada',\n",
        "                                 'jakie przedmioty prowadzi']\n",
        "        check = self.check_if_contains(prompt_lower, courses_conduct_forms)\n",
        "        if check:\n",
        "            person = ' '.join(prompt.split()[len(check.split()):])\n",
        "            closest = self.find_closest(person, courses.people, surnames=True)\n",
        "            if closest:\n",
        "                full_person = closest\n",
        "            else:\n",
        "                return f'Niestety, {person} nie prowadzi na Instytucie zajęć w tym semestrze.'\n",
        "\n",
        "            found_courses = courses.get_courses_person(full_person)\n",
        "            to_print = f'{full_person} prowadzi:\\n'\n",
        "            for c in found_courses:\n",
        "                to_print += f\"\\t{c[0]}, {c[1]}, {c[2][0]} \\n\"\n",
        "            return to_print\n",
        "\n",
        "        # kursy z efektem, kursy z tagiem, kursy ze znacznikiem\n",
        "        effects_prompts = ['jakie kursy mają efekt', 'jakie przedmioty mają efekt']\n",
        "        tags_prompts = ['jakie kursy mają tag', 'jakie przedmioty mają tag']\n",
        "        type_prompts = ['jakie kursy mają znacznik', 'jakie przedmioty mają znacznik']\n",
        "\n",
        "        prompts = [effects_prompts, tags_prompts, type_prompts]\n",
        "        filter_keys = ['allEffects', 'allTags', 'allTypes']\n",
        "\n",
        "        fail_texts = ['Niestety, nie ma przedmiotów z efektem', 'Niestety, nie ma przedmiotów z tagiem',\n",
        "                      'Niestety, nie ma przedmiotów ze znacznikiem']\n",
        "        success_texts = ['Przedmioty z efektem', 'Przedmioty z tagiem',\n",
        "                      'Przedmioty ze znacznikiem']\n",
        "\n",
        "        get_methods = [courses.get_courses_effect, courses.get_courses_tag, courses.get_courses_type]\n",
        "\n",
        "        for prompts_option, filter_key, fail_text, success_text, get_method in zip(prompts, filter_keys, \n",
        "                                                                        fail_texts, success_texts, get_methods):\n",
        "            check = self.check_if_contains(prompt_lower, prompts_option)\n",
        "            if check:\n",
        "                current = ' '.join(prompt.split()[len(check.split()):])\n",
        "                if filter_key == 'allTypes':\n",
        "                    if len(current) <= 5:\n",
        "                        current = self.convert_type(current)\n",
        "                closest = self.find_closest(current, courses.filters[filter_key].values())\n",
        "                if closest:\n",
        "                    full_current = closest\n",
        "                else:\n",
        "                    return f'{fail_text} {current}.'\n",
        "\n",
        "                found_courses = get_method(full_current)\n",
        "                to_print = f\"{success_text} {full_current}:\\n\"\n",
        "                for c in found_courses:\n",
        "                    to_print += f\"\\t{c},\\n\"\n",
        "                return to_print\n",
        "\n",
        "        # godziny przedmiotu\n",
        "        courses_hours_forms = ['kiedy odbywa się', 'o której godzinie jest', 'o której godzinie są', 'gdzie jest',\n",
        "                               'gdzie odbywa się', 'gdzie odbywają się']\n",
        "        check = self.check_if_contains(prompt_lower, courses_hours_forms)\n",
        "        if check:\n",
        "            course = ' '.join(prompt.split()[len(check.split()):])\n",
        "            closest = self.find_closest(course, courses.courses_names)\n",
        "            if closest:\n",
        "                full_course = closest\n",
        "            else:\n",
        "                return f'Niestety, przedmiot {course} nie jest prowadzony w tym semestrze.'\n",
        "\n",
        "            found_course = courses.get_course_instances(full_course)\n",
        "            to_print = f'Godziny i sale przedmiotu {full_course} to:\\n'\n",
        "            for c in found_course:\n",
        "                to_print += f'\\t{c[0]}\\n'\n",
        "                for inst in c[1]:\n",
        "                    to_print += f\"\\t\\t{inst[0]}, {inst[1]}\\n\"\n",
        "            return to_print\n",
        "        \n",
        "        courses_prompts = ['gdzie mogę się zapisać na', 'jaka jest strona przedmiotu']\n",
        "        check = self.check_if_contains(prompt_lower, courses_prompts)\n",
        "        if check:\n",
        "            course = ' '.join(prompt.split()[len(check.split()):])\n",
        "            closest = self.find_closest(course, courses.courses_names)\n",
        "            if closest:\n",
        "                full_course = closest\n",
        "            else:\n",
        "                return f'Niestety, przedmiot {course} nie jest prowadzony w tym semestrze.'\n",
        "\n",
        "            web_adr = \"https://zapisy.ii.uni.wroc.pl/courses/\" \n",
        "            web_adr += '-'.join(full_course.lower().translate(str.maketrans('', '', string.punctuation)).split())\n",
        "            web_adr += '-202223-letni'\n",
        "            return f\"Strona przedmioty {full_course} to {web_adr}\"\n",
        "\n",
        "        # informacje o wymaganiach do skonczenia studiow\n",
        "        courses_prompts = ['jakie są wymagania do zakończenia studiów']\n",
        "        check = self.check_if_contains(prompt_lower, courses_prompts)\n",
        "        if check:\n",
        "            return QUESTION_DEGREE   \n",
        "\n",
        "\n",
        "        courses_prompts = ['jaki przedmiot warto zrobić po', 'podobny przedmiot do']\n",
        "        check = self.check_if_contains(prompt_lower, courses_prompts)\n",
        "        if check:\n",
        "            course = ' '.join(prompt.split()[len(check.split()):])\n",
        "            closest = self.find_closest(course, courses.courses_names)\n",
        "            if closest:\n",
        "                full_course = closest\n",
        "            else:\n",
        "                return f'Niestety, przedmiot {course} nie jest prowadzony w tym semestrze.'\n",
        "\n",
        "            to_print = f\"Po zaliczeniu {full_course} warto się zastanowić na:\\n\"\n",
        "            \n",
        "            recommended = recommender.find_best_course(full_course)\n",
        "            for c in recommended:\n",
        "                to_print += f'\\t{c}\\n'\n",
        "            return to_print\n",
        "\n",
        "\n",
        "        return None\n",
        "\n",
        "    def rules_details(self):\n",
        "        study_type = ''\n",
        "        req_type = ''\n",
        "\n",
        "        prompt = input('Zosia: Jaki stopień studiów Cię interesuje?: ')\n",
        "        prompt = prompt.translate(str.maketrans('', '', string.punctuation))\n",
        "        prompt_lower = prompt.lower()\n",
        "\n",
        "        # get stopien\n",
        "        prompts_first = ['pierwszy', '1', 'licencjackie', 'inżynierskie']\n",
        "        prompts_second = ['drugi', 'magisterskie', '2', 'ii']\n",
        "        \n",
        "        check1 = self.check_if_contains(prompt_lower, prompts_first, error_size=0)\n",
        "        check2 = self.check_if_contains(prompt_lower, prompts_second, error_size=0)\n",
        "        study_rules = StudyRules()\n",
        "        if check1:\n",
        "            chosen_rules = study_rules.data_first_degree()\n",
        "        elif check2:\n",
        "            chosen_rules = study_rules.data_second_degree()\n",
        "        \n",
        "        # first degree only\n",
        "        if check1:\n",
        "            degree_num = 1\n",
        "            prompt1 = 'Interesują Cię studia licencjackie czy inżynierskie?: '\n",
        "            prompts_option1 = ['licencjackie']\n",
        "            prompts_option2 = ['inżynierskie']\n",
        "\n",
        "        if check2:\n",
        "            degree_num = 2\n",
        "            prompt1 = 'Mówisz o studiach trzysemestralnych czy czterosemestralnych?: '\n",
        "            prompts_option1 = ['trzysemestralnych']\n",
        "            prompts_option2 = ['czterosemestralnych']\n",
        "\n",
        "        prompt_degree = input(f'Zosia: {prompt1}')\n",
        "        check11 = self.check_if_contains(prompt_degree, prompts_option1)\n",
        "        check12 = self.check_if_contains(prompt_degree, prompts_option2)\n",
        "        if check11:\n",
        "            study_type = 0\n",
        "            study_name = prompts_option1[0]\n",
        "        elif check12:\n",
        "            study_type = 1\n",
        "            study_name = prompts_option2[0]\n",
        "\n",
        "        prompt_req = input('Zosia: Chcesz dowiedzieć się o obowiązkach, ECTS czy innych wymaganiach?: ')\n",
        "        if 'obowiązkach' in prompt_req.lower():\n",
        "            to_print = chosen_rules.compulsory_courses\n",
        "            print(f'Zosia: Przedmioty obowiązkowe dla stopień {degree_num}, {study_name}')\n",
        "            for item in chosen_rules.compulsory_courses:\n",
        "                print(f'\\t{item}')\n",
        "        elif 'ects' in prompt_req.lower():\n",
        "            print(f'Zosia: Wymagane ECTS dla stopień {degree_num}, {study_name}')\n",
        "            for key, value in chosen_rules.ects_numbers.items():\n",
        "                print(f'\\t{key}: {value[study_type]}')\n",
        "        else:\n",
        "            print(f'Zosia: Inne wymagania dla stopień {degree_num}, {study_name}')\n",
        "            for key, value in chosen_rules.other_requirements.items():\n",
        "                print(f'\\t{key}: {value[study_type]}')\n",
        "            \n",
        "\n",
        "rules = RuleSystem()\n",
        "\n",
        "# rules.choose_rule('gdzie mogę się zapisać')\n",
        "# rules.choose_rule('o której godzinie jest bazy danych')\n",
        "# rules.choose_rule('jaka jest strona Algorytmy i struktury danych')\n",
        "# rules.choose_rule('jakie kursy mają efekt Sieci komputer')\n",
        "# rules.choose_rule('jakie kursy mają tag data science')\n",
        "# rules.choose_rule('jakie kursy mają znacznik i2.t')\n"
      ],
      "metadata": {
        "id": "su9trI7hB2ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study_rules = StudyRules()\n",
        "chosen_rules = study_rules.data_first_degree()\n",
        "chosen_rules.compulsory_courses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tnkum8_5p0zZ",
        "outputId": "e75b859e-589f-46dd-b651-f6bba39c464b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Analiza matematyczna',\n",
              " 'Logika dla informatyków',\n",
              " 'Algebra',\n",
              " 'Metody programowania',\n",
              " 'Analiza numeryczna',\n",
              " 'Matematyka dyskretna (L)',\n",
              " 'Algorytmy i struktury danych (L)']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ENDING_KEY_WORD = 'Do zobaczenia!'\n",
        "ENDING_FAREWELL = 'Do następnego!'\n",
        "\n",
        "rules = RuleSystem()\n",
        "\n",
        "def keep_constant_context_length(current_prompt, context, tokenizer, max_len=256):\n",
        "    \"\"\"\n",
        "    keep constant and relatively short conversation context\n",
        "    \"\"\"\n",
        "    current_context_len = len(tokenizer.encode(current_prompt)) # add eos ??\n",
        "    new_context = []\n",
        "    i = len(context) - 2\n",
        "    # print(context)\n",
        "    while current_context_len < max_len and i >= 0:\n",
        "        current_context_len +=  len(tokenizer.encode(\"</s> <s>\" + context[i]))\n",
        "        new_context.append(context[i])\n",
        "        i -= 1\n",
        "\n",
        "    new_context.reverse()\n",
        "    if new_context:\n",
        "        return '</s> <s>'.join(new_context + \\\n",
        "                [current_prompt])\n",
        "    else:        \n",
        "        return '<s>' + current_prompt + '</s>'\n",
        "\n",
        "\n",
        "def chatbot(lang_model, translator, translate=True):\n",
        "    \"\"\"\n",
        "    main function to deliver chabot to the user\n",
        "    \"\"\"\n",
        "    print(f'Witaj! Powiedz, o czym chciałbyś porozmawiać?')\n",
        "\n",
        "    conversation_context = []\n",
        "    chat_history_ids = []\n",
        "    iter = 0\n",
        "    while True:\n",
        "        prompt = input('Ty :')\n",
        "\n",
        "        # conversation ending\n",
        "        if prompt == ENDING_KEY_WORD:\n",
        "            print(ENDING_FAREWELL)\n",
        "            break\n",
        "\n",
        "        out = rules.choose_rule(prompt)\n",
        "        if out:\n",
        "            if out == QUESTION_DEGREE:\n",
        "                rules.rules_details()\n",
        "            else:\n",
        "                 print(out)\n",
        "            continue\n",
        "\n",
        "        # translation part\n",
        "        current_lang = LANGUAGE.predict_en_pl(prompt)\n",
        "        if translate and current_lang != 'en':\n",
        "            prompt = translator.translate(prompt, source_language='pl', target_language='en-us')\n",
        "\n",
        "        conversation_context.append(prompt)\n",
        "\n",
        "        prompt = keep_constant_context_length(prompt, conversation_context, lang_model.tokenizer, max_len=100)\n",
        "                \n",
        "        answer = lang_model.generate_output(prompt)\n",
        "        answer = answer[0].strip()\n",
        "\n",
        "        # second translation part\n",
        "        if translate and current_lang != 'en':\n",
        "            answer = translator.translate(answer, source_language='en', target_language='pl')\n",
        "            print(' ', answer)\n",
        "\n",
        "        # add answer to the context\n",
        "        conversation_context.append(answer)\n",
        "        iter +=1\n",
        "        "
      ],
      "metadata": {
        "id": "caBZ2gTtzAdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(LM2, translator, translate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3n6K3ZMa6Wj",
        "outputId": "7292bf8e-719f-4ced-fb27-ea4d6e964b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Witaj! Powiedz, o czym chciałbyś porozmawiać?\n",
            "Ty :jaka jest strona przedmiotu bazy danych\n",
            "Strona przedmioty Bazy danych to https://zapisy.ii.uni.wroc.pl/courses/bazy-danych-202223-letni\n",
            "Ty :Do zobaczenia!\n",
            "Do następnego!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(LM2, translator, translate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip6S6dipb_PH",
        "outputId": "67939dc4-45df-4f3d-e5c1-f95b2387d889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Witaj! Powiedz, o czym chciałbyś porozmawiać?\n",
            "Ty :co tam słychać?\n",
            "  Nic wielkiego, po prostu myślę o wszystkich dobrych chwilach, które miałem z moją rodziną, kiedy byłem młodszy.\n",
            "Ty :o  gdzie mieszkałeś?\n",
            "  Mieszkam w Stanach Zjednoczonych. A ty? Czym się zajmujesz w życiu?\n",
            "Ty :Do zobaczenia!\n",
            "Do następnego!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(LM2, translator, translate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-lRG22ZzAbX",
        "outputId": "ff3a948c-f9a9-4674-f51f-17011e34666a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Witaj! Powiedz, o czym chciałbyś porozmawiać?\n",
            "Ty :jaki przedmiot warto zrobić po projekt: deep learning\n",
            "Po zaliczeniu Projekt: Deep Learning warto się zastanowić na:\n",
            "\tNeural Networks and Natural Language Processing\n",
            "\tAdvanced Data Mining\n",
            "\tSieci komputerowe\n",
            "\n",
            "Ty :jaki przedmiot warto zrobić po Architektury systemów komputerowych\n",
            "Po zaliczeniu Architektury systemów komputerowych warto się zastanowić na:\n",
            "\tMetody programowania\n",
            "\tAdvanced Distributed Algorithms\n",
            "\tKurs administrowania systemem Linux\n",
            "\n",
            "Ty :Course on Biomedical Image Analysis for Computer ScientistsCourse on Biomedical Image Analysis for Computer Scientists\n",
            "Ty :jak się czujesz?\n",
            "  Kocham komputery. Pracuję na nich na co dzień. Co robisz w pracy?\n",
            "Ty :ja też kocham komputery!\n",
            "  Ja też ją kocham! Uwielbiam fakt, że jest to gałąź matematyki\n",
            "Ty :jaki przedmiot warto zrobić po Course on Biomedical Image Analysis for Computer Scientists\n",
            "Po zaliczeniu Course on Biomedical Image Analysis for Computer Scientists warto się zastanowić na:\n",
            "\tAdvanced Automata Theory\n",
            "\tKrzywe i powierzchnie w grafice komputerowej\n",
            "\tPrzetwarzanie Obrazów / Digital Image Processing\n",
            "\n",
            "Ty :Do zobaczenia!\n",
            "Do następnego!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(LM2, translator, translate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU1zwpNXSZP9",
        "outputId": "f59294f6-f0a2-47de-b906-b7ec57ebae4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Witaj! Powiedz, o czym chciałbyś porozmawiać?\n",
            "Ty :jakie są wymagania do zakończenia studiów\n",
            "Powiedz proszę, jaki stopień studiów Cię interesuje\n",
            "Jaki stopień studiów Cię interesuje?: 1\n",
            "Interesują Cię studia licencjackie czy inżynierskie?: licencjackie\n",
            "Chcesz dowiedzieć się o obowiązkach, ECTS czy innych wymaganiach?: ects\n",
            "Wymagane ECTS dla stopień 1, licencjackie\n",
            "\tmin. liczba ECTS: 180 ECTS\n",
            "\tza pracę dyplomową i egzamin: 10 ECTS\n",
            "Ty :jakie przedmioty mają tag data science\n",
            "Przedmioty z tagiem Data Science:\n",
            "\tAdvanced Data Mining,\n",
            "\tNeural Networks and Natural Language Processing,\n",
            "\tNumerical Optimization,\n",
            "\n",
            "Ty :a jakie przedmioty mają tag ekonomia?\n",
            "Przedmioty z tagiem Ekonomia:\n",
            "\tUsługi finansowe,\n",
            "\tUsługi finansowe (w),\n",
            "\n",
            "Ty :jakie zajęcia prowadzi Jurdziński?\n",
            "Tomasz Jurdziński prowadzi:\n",
            "\tAdvanced Distributed Algorithms, Wykłady, cz 10:00-12:00 (s. 105) \n",
            "\tAdvanced Distributed Algorithms, Ćwiczenia, cz 14:00-16:00 (s. 105) \n",
            "\n",
            "Ty :a jakie zajęcia prowadzi Leszek Grocholki?\n",
            "Niestety, prowadzi Leszek Grocholki nie prowadzi na Instytucie zajęć w tym semestrze.\n",
            "Ty :a jakie zajęcia prowadzi Leszek Grocholski?\n",
            "Niestety, prowadzi Leszek Grocholski nie prowadzi na Instytucie zajęć w tym semestrze.\n",
            "Ty :jakie zajęcia prowadzi Leszek Grocholki?\n",
            "Leszek Grocholski prowadzi:\n",
            "\tProjekt dyplomowy, Projekty, wt 14:00-16:00 (s. 107) \n",
            "\tProseminarium: Testowanie oprogramowania, Seminaria, cz 18:00-20:00 (s. 4) \n",
            "\tSeminar: Software Engineering, Seminaria, cz 16:00-18:00 (s. 4) \n",
            "\tTestowanie gier, Wykłady, wt 18:00-20:00 (s. 140) \n",
            "\tTestowanie gier, Ćwiczenio-pracownie, cz 14:00-16:00 (s. 4, 7) \n",
            "\n",
            "Ty :'o której godzinie jest scal in practice\n",
            "Godziny i sale przedmiotu Scala in Practice to:\n",
            "\tPracownie\n",
            "\t\tMichał Kowalczykiewicz, śr 18:00-20:00 (s. wirtualna1)\n",
            "\t\tMichał Kowalczykiewicz, cz 18:00-20:00 (s. )\n",
            "\t\tDariusz Biernacki, pn 14:00-16:00 (s. 137)\n",
            "\tWykłady\n",
            "\t\tMichał Kowalczykiewicz, wt 18:00-20:00 (s. wirtualna4)\n",
            "\n",
            "Ty :jakie kursy mają znacznik i2z\n",
            "Przedmioty ze znacznikiem I2.Z - zastosowania inf.:\n",
            "\tAdvanced Data Mining,\n",
            "\tKryptografia,\n",
            "\tNeural Networks and Natural Language Processing,\n",
            "\tPrzetwarzanie Obrazów / Digital Image Processing,\n",
            "\n",
            "Ty :Na jakiejs stronie mogę się zapisać na przedmioty?\n",
            "Zapisywać się na przedmioty i nie tylko można na stronie:\n",
            "https://zapisy.ii.uni.wroc.pl/'\n",
            "Ty :Bardzo dziękuję za pomoc!\n",
            "Zosia:  Nie ma za co.  Mam nadzieję, że masz wspaniały dzień.  Dbaj o siebie.\n",
            "Ty :Do zobaczenia!\n",
            "Do następnego!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aK23o5jzjDMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EciirDibdybi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}